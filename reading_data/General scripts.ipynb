{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25baa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02975dd",
   "metadata": {},
   "source": [
    "### some code to build up the GROWL catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b205b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /Volumes/GROWL/GROWL_bps/Boesky24/alpha10_beta0_75/COMPAS_Output_Weighted.h5 not found\n",
      "Warning: No HDF5 files found in /Volumes/GROWL/GROWL_bps/Romagnolo24/ST_ouput\n",
      "GROWL Catalog Summary:\n",
      "==================================================\n",
      "\n",
      "Author: Boesky24\n",
      "  File: COMPAS_Output_Weighted.h5\n",
      "  Datasets (10):\n",
      "    - alpha0_1beta0_25\n",
      "    - alpha0_1beta0_5\n",
      "    - alpha0_1beta0_75\n",
      "    - alpha0_5beta0_25\n",
      "    - alpha0_5beta0_5\n",
      "    - alpha0_5beta0_75\n",
      "    - alpha10_beta0_5\n",
      "    - alpha10_beta0_75\n",
      "    - alpha2_beta0_5\n",
      "    - alpha2beta0_25\n",
      "\n",
      "Datasets for Boesky24:\n",
      "  - alpha0_1beta0_25\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_1beta0_25/COMPAS_Output_Weighted.h5\n",
      "  - alpha0_1beta0_5\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_1beta0_5/COMPAS_Output_Weighted.h5\n",
      "  - alpha0_1beta0_75\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_1beta0_75/COMPAS_Output_Weighted.h5\n",
      "  - alpha0_5beta0_25\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_5beta0_25/COMPAS_Output_Weighted.h5\n",
      "  - alpha0_5beta0_5\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_5beta0_5/COMPAS_Output_Weighted.h5\n",
      "  - alpha0_5beta0_75\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha0_5beta0_75/COMPAS_Output_Weighted.h5\n",
      "  - alpha10_beta0_5\n",
      "    Path: /Volumes/GROWL/GROWL_bps/Boesky24/alpha10_beta0_5/COMPAS_Output_Weighted.h5\n",
      "  - alpha10_beta0_75\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataset 'alpha10_beta0_75' not found for author 'Boesky24'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 161\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Get full file path\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrowl_catalog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBoesky24\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m, in \u001b[0;36mget_file_path\u001b[0;34m(catalog, author, dataset)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in catalog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m catalog[author][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found for author \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m path \u001b[38;5;241m=\u001b[39m catalog[author][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m][dataset]\n\u001b[1;32m     86\u001b[0m file_name \u001b[38;5;241m=\u001b[39m catalog[author][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset 'alpha10_beta0_75' not found for author 'Boesky24'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_growl_catalog(base_path='/Volumes/GROWL/GROWL_bps'):\n",
    "    \"\"\"\n",
    "    Build a dictionary structure for GROWL catalog with authors and their datasets.\n",
    "    \n",
    "    Structure:\n",
    "    {\n",
    "        'author_name': {\n",
    "            'datasets': ['dataset1', 'dataset2', ...],\n",
    "            'file_name': 'COMPAS_Output_Weighted.h5',\n",
    "            'paths': {\n",
    "                'dataset1': '/Volumes/GROWL/Boesky24/alpha0_1beta0_25/',\n",
    "                'dataset2': '/Volumes/GROWL/Boesky24/alpha0_1beta0_5/'\n",
    "            }\n",
    "            'labels':{'dataset1': r'$\\alpha 0.1 \\ \\beta=0.25$',\n",
    "                      'dataset2': r'$\\alpha 0.1 \\ \\beta=0.5$'\n",
    "            \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    catalog = {}\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Base path {base_path} does not exist\")\n",
    "        return catalog\n",
    "    \n",
    "    # Get all author directories\n",
    "    author_dirs = [d for d in os.listdir(base_path) \n",
    "                  if os.path.isdir(os.path.join(base_path, d)) and not d.startswith('.')]\n",
    "    \n",
    "    for author in author_dirs:\n",
    "        author_path = os.path.join(base_path, author)\n",
    "        \n",
    "        # Get all dataset directories for this author\n",
    "        dataset_dirs = [d for d in os.listdir(author_path) \n",
    "                       if os.path.isdir(os.path.join(author_path, d)) and not d.startswith('.')]\n",
    "        \n",
    "        if not dataset_dirs:\n",
    "            continue\n",
    "            \n",
    "        # Find the common HDF5 file name by checking the first dataset\n",
    "        first_dataset_path = os.path.join(author_path, dataset_dirs[0])\n",
    "        h5_files = glob.glob(os.path.join(first_dataset_path, '*.h5'))\n",
    "        \n",
    "        if not h5_files:\n",
    "            print(f\"Warning: No HDF5 files found in {first_dataset_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Assume the first HDF5 file is the standard one\n",
    "        file_name = os.path.basename(h5_files[0])\n",
    "        \n",
    "        # Build paths dictionary\n",
    "        paths = {}\n",
    "        for dataset in dataset_dirs:\n",
    "            dataset_path = os.path.join(author_path, dataset)\n",
    "            # Verify the HDF5 file exists in this dataset\n",
    "            expected_file = os.path.join(dataset_path, file_name)\n",
    "            if os.path.exists(expected_file):\n",
    "                paths[dataset] = dataset_path + '/'\n",
    "            else:\n",
    "                print(f\"Warning: {expected_file} not found\")\n",
    "        \n",
    "        catalog[author] = {\n",
    "            'datasets': sorted(dataset_dirs),\n",
    "            'file_name': file_name,\n",
    "            'paths': paths\n",
    "        }\n",
    "    \n",
    "    return catalog\n",
    "\n",
    "def get_file_path(catalog, author, dataset):\n",
    "    \"\"\"\n",
    "    Get the full path to an HDF5 file for a specific author and dataset.\n",
    "    \"\"\"\n",
    "    if author not in catalog:\n",
    "        raise ValueError(f\"Author '{author}' not found in catalog\")\n",
    "    \n",
    "    if dataset not in catalog[author]['paths']:\n",
    "        raise ValueError(f\"Dataset '{dataset}' not found for author '{author}'\")\n",
    "    \n",
    "    path = catalog[author]['paths'][dataset]\n",
    "    file_name = catalog[author]['file_name']\n",
    "    return os.path.join(path, file_name)\n",
    "\n",
    "def list_authors(catalog):\n",
    "    \"\"\"Get list of all authors.\"\"\"\n",
    "    return list(catalog.keys())\n",
    "\n",
    "def list_datasets(catalog, author):\n",
    "    \"\"\"Get list of all datasets for a specific author.\"\"\"\n",
    "    if author not in catalog:\n",
    "        raise ValueError(f\"Author '{author}' not found in catalog\")\n",
    "    return catalog[author]['datasets']\n",
    "\n",
    "def print_catalog_summary(catalog):\n",
    "    \"\"\"Print a summary of the catalog structure.\"\"\"\n",
    "    print(\"GROWL Catalog Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for author in sorted(catalog.keys()):\n",
    "        print(f\"\\nAuthor: {author}\")\n",
    "        print(f\"  File: {catalog[author]['file_name']}\")\n",
    "        print(f\"  Datasets ({len(catalog[author]['datasets'])}):\")\n",
    "        for dataset in catalog[author]['datasets']:\n",
    "            print(f\"    - {dataset}\")\n",
    "\n",
    "# Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Build the catalog\n",
    "#     growl_catalog = build_growl_catalog()\n",
    "    \n",
    "#     # Print summary\n",
    "#     print_catalog_summary(growl_catalog)\n",
    "    \n",
    "#     # Example iterations:\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"Example iterations:\")\n",
    "    \n",
    "#     # Iterate over authors\n",
    "#     print(\"\\nAuthors:\")\n",
    "#     for author in list_authors(growl_catalog):\n",
    "#         print(f\"  - {author}\")\n",
    "    \n",
    "#     # Iterate over datasets for a specific author (e.g., Boesky24)\n",
    "#     if 'Boesky24' in growl_catalog:\n",
    "#         print(f\"\\nDatasets for Boesky24:\")\n",
    "#         for dataset in list_datasets(growl_catalog, 'Boesky24'):\n",
    "#             print(f\"  - {dataset}\")\n",
    "#             # Get full file path\n",
    "#             file_path = get_file_path(growl_catalog, 'Boesky24', dataset)\n",
    "#             print(f\"    Path: {file_path}\")\n",
    "    \n",
    "#     # Example of accessing a specific file\n",
    "#     print(\"\\nExample file access:\")\n",
    "#     try:\n",
    "#         example_path = get_file_path(growl_catalog, 'Boesky24', 'alpha0_1beta0_25')\n",
    "#         print(f\"Boesky24 alpha0_1beta0_25 file: {example_path}\")\n",
    "#     except (ValueError, KeyError) as e:\n",
    "#         print(f\"Could not access example file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Build the catalog\n",
    "growl_catalog = build_growl_catalog()\n",
    "\n",
    "# Print summary\n",
    "print_catalog_summary(growl_catalog)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'Boesky24' in growl_catalog:\n",
    "    print(f\"\\nDatasets for Boesky24:\")\n",
    "    for dataset in list_datasets(growl_catalog, 'Boesky24'):\n",
    "        print(f\"  - {dataset}\")\n",
    "        # Get full file path\n",
    "        file_path = get_file_path(growl_catalog, 'Boesky24', dataset)\n",
    "        print(f\"    Path: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b157286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
